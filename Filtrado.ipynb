{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adquisición de Datos\n",
    "Primero se realizó una generación y búsqueda de datos; pera obtener los mensajes que teminarán siendo integrados en nuestro *dataset* de mensajes; para lo cual, cargamos la informacion haciendo uso de `pandas`.  \n",
    "\n",
    "Estos datos ya fueron previamente saneados, por lo que no es muy necesario darles un tratemiento programatico de inmediato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_clasism = pd.read_csv('./datasets/1_clasism.csv')\n",
    "df_racism = pd.read_csv('./datasets/2_racism.csv')\n",
    "df_sexism = pd.read_csv('./datasets/3_sexism.csv')\n",
    "df_other = pd.read_csv('./datasets/4_other.csv')\n",
    "df_inappropriate = pd.read_csv('./datasets/5_inappropriate_content.csv')\n",
    "df_none = pd.read_csv('./datasets/6_none_of_the_above.csv')\n",
    "\n",
    "df_clasism.columns = ['text']\n",
    "df_racism.columns = ['text']\n",
    "df_sexism.columns = ['text']\n",
    "df_other.columns = ['text']\n",
    "df_inappropriate.columns = ['text']\n",
    "df_none.columns = ['text']\n",
    "\n",
    "df_clasism['class'] = 1\n",
    "df_racism['class'] = 2\n",
    "df_sexism['class'] = 3\n",
    "df_other['class'] = 4\n",
    "df_inappropriate['class'] = 5\n",
    "df_none['class'] = 6\n",
    "\n",
    "dataset = pd.concat([df_clasism, df_racism, df_sexism, df_other, df_inappropriate, df_none], ignore_index=True)\n",
    "\n",
    "dataset.head(), dataset.shape\n",
    "\n",
    "combined_file_path = './datasets/dataset.csv'\n",
    "dataset.to_csv(combined_file_path, index=False , mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización\n",
    "\n",
    "Ya que se unificó desde diversas fuentes la información obtenida, podemos hacer un proceso simple de limpieza de datos adicional.\n",
    "\n",
    "Además, se hace que el texto almacenado esté en letras minusculas, para facilitar el tratamiento de la información y otras modificaciones futuras.  \n",
    "\n",
    "También, se elimina particularmente una palabra que no brinda informacion del mensaje, sino que hace referencia (de forma anonima) al receptor y/o emisor del mensaje, lo cual no nos es de mucha utilidad, pues no nos permite obtener información valiosa respecto la intención del resto del mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "5    489\n",
       "3    474\n",
       "2    454\n",
       "4    449\n",
       "6    449\n",
       "1    414\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(combined_file_path)\n",
    "\n",
    "class_counts = data['class'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public education is in decline luckily my kids...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it bothers me to have to stand in line like th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the poor are only poor because they want to be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you cant afford good wine better not to dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the service in this restaurant is terrible whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  public education is in decline luckily my kids...      1\n",
       "1  it bothers me to have to stand in line like th...      1\n",
       "2  the poor are only poor because they want to be...      1\n",
       "3  if you cant afford good wine better not to dri...      1\n",
       "4  the service in this restaurant is terrible whe...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que todas las letas sean minusculas\n",
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "data['text'] = data['text'].apply(to_lower)\n",
    "\n",
    "# Quitar signos de puntuacion\n",
    "data['text'] = data['text'].str.replace(r\"[^a-z0-9\\s]\", \"\" , regex=True)\n",
    "\n",
    "# Guarda el resultado en un nuevo archivo CSV\n",
    "data.to_csv(combined_file_path, index=False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que se tienen los textos en una forma adecuada y agradable para trabajar sobre ellos, podemos empezar a transformalos con un enfoque más apegado al *Procesamiento Natural de Lenguaje*; primero, para tener un procesamiento más optimo, retiramos aquellas palabras que no aportan información relevante, por lo cual retiraremos las **stopwords** encontradas en los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public education is in decline luckily my kids...</td>\n",
       "      <td>1</td>\n",
       "      <td>[public, education, is, in, decline, luckily, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it bothers me to have to stand in line like th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[it, bothers, me, to, have, to, stand, in, lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the poor are only poor because they want to be...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, poor, are, only, poor, because, they, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you cant afford good wine better not to dri...</td>\n",
       "      <td>1</td>\n",
       "      <td>[if, you, cant, afford, good, wine, better, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the service in this restaurant is terrible whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, service, in, this, restaurant, is, terri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class  \\\n",
       "0  public education is in decline luckily my kids...      1   \n",
       "1  it bothers me to have to stand in line like th...      1   \n",
       "2  the poor are only poor because they want to be...      1   \n",
       "3  if you cant afford good wine better not to dri...      1   \n",
       "4  the service in this restaurant is terrible whe...      1   \n",
       "\n",
       "                                              tokens  \n",
       "0  [public, education, is, in, decline, luckily, ...  \n",
       "1  [it, bothers, me, to, have, to, stand, in, lin...  \n",
       "2  [the, poor, are, only, poor, because, they, wa...  \n",
       "3  [if, you, cant, afford, good, wine, better, no...  \n",
       "4  [the, service, in, this, restaurant, is, terri...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Obtener la lista de stopwords en ingles\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Funcion para tokenizar las palabras\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "data['tokens'] = data['text'].apply(tokenize)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que se ha tokenizado exitosamente el texto, se aplica el retirado de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public education is in decline luckily my kids...</td>\n",
       "      <td>1</td>\n",
       "      <td>[public, education, decline, luckily, kids, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it bothers me to have to stand in line like th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bothers, stand, line, like, rest, plebs, dont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the poor are only poor because they want to be...</td>\n",
       "      <td>1</td>\n",
       "      <td>[poor, poor, want, made, hard, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you cant afford good wine better not to dri...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cant, afford, good, wine, better, drink, anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the service in this restaurant is terrible whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[service, restaurant, terrible, manager, deman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class  \\\n",
       "0  public education is in decline luckily my kids...      1   \n",
       "1  it bothers me to have to stand in line like th...      1   \n",
       "2  the poor are only poor because they want to be...      1   \n",
       "3  if you cant afford good wine better not to dri...      1   \n",
       "4  the service in this restaurant is terrible whe...      1   \n",
       "\n",
       "                                              tokens  \n",
       "0  [public, education, decline, luckily, kids, go...  \n",
       "1  [bothers, stand, line, like, rest, plebs, dont...  \n",
       "2               [poor, poor, want, made, hard, work]  \n",
       "3  [cant, afford, good, wine, better, drink, anyt...  \n",
       "4  [service, restaurant, terrible, manager, deman...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Definir una función para eliminar las stopwords de un texto\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Aplicamos la función a la columna 'tokens' del DataFrame\n",
    "data['tokens'] = data['tokens'].apply(remove_stopwords)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que aparentemente se ha completado la tokenización y retiro de stepwords exitosamente, procedo a realizar ahora una lematización, de modo que las palabras principales sean \"recortadas\" a su forma fundamental, y se pueda operar sobre ellas de mejor manera.  \n",
    "Se prefiere *lematización* sobre *stemming*, pues se desea preservar una raíz adecuada de la palabra; conservando cuanto se pueda, sin alterar los posibles significados o creando accidentalmente palabras inexistentes. Además, que en casos de identificación de motivo e intención, se considera que es más adecuado contar con cuanto contexto y sensibilidad sea adecuado, por lo cual se descarta *stemming*.\n",
    "### Correccion\n",
    "Tras comparar los dataframe resultantes de solo efectuar lematizacion, y solo retirar las stopword, se obtuvo el mismo resultado, por lo que, aunque en planteamiento es adecuado primero retirar las stopword, y posteriormente lematizar, a efectos de este proyecto es más útil simplemente retirar las stopword."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
